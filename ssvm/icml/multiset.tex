%!TEX root = main.tex
%\section{Recommending sequences}
\secmoveup
\section{The sequence recommendation problem}
\label{sec:recseq}
\textmoveup

We begin with an overview of the sequence recommendation problem, before presenting our model.
Consider first the following abstract
\emph{structured recommendation} problem:
given an input query $\x \in \mathcal{X}$ -- representing for example a user, a location, or some ``seed'' item --
we wish to recommend one or more \emph{structured outputs} $\y \in \mathcal{Y}$ according to a learned \emph{score function} $f(\x,\y)$.
To learn a suitable $f$,
we are provided as input a training set
%$(\x\pb{i}, \{ \y\pb{ij} \}_{j=1:n^i})$, $i=1:n$,
$\{ ( \x\pb{i}, \{ \y\pb{ij} \}_{j=1}^{n^i} ) \}_{i=1}^{n}$,
comprising a collection of inputs $\x\pb{i}$ with an associated \emph{set} of output structures $\{ \y\pb{ij} \}$.
As an example, this might represent a collection of users in a city, along with a set of trajectories that the user has visited.

For this work, we assume the output $\y$ is a \emph{sequence} of $l$ points, denoted $y_{1:l}$
where each $y_i$ belongs to some fixed set (e.g.\ places of interest in a city).
We call the resulting specialisation the \emph{sequence recommendation} problem,
and this shall be our primary interest in this paper.
The assumption that $\y$ is a sequence does not limit the generality of our approach,
as inferring $\y$ of other structure can be achieved using corresponding inference and loss-augmented inference algorithms~\cite{joachims2009predicting}.  %LX - this sentence can be cut or merged above

There are notable differences between the sequence recommendation problem and %what is being solved in
the standard problems considered in structured prediction and recommender systems.
%This setting generalises from structured prediction and recommendation problems in the following ways.
These differences bring unique challenges for both inference and learning.
In a typical structured prediction setting, the goal is to learn from a collection of $n$
input vector and output sequence tuples %$(\x\pb{i}, \y\pb{i})$, $i=1:n$.
$\{ (\x\pb{i}, \y\pb{i}) \}_{i = 1}^n$. Here,
for each distinct input $\x\pb{i}$ there is usually one \emph{unique} output sequence $\y\pb{i}$.
In a typical sequence recommendation problem, however, we expect that %learn from
%tuples $(\x\pb{i}, \{ y\pb{ij} \}_{j=1:n^i})$, $i=1:n$. That is to say,
for each input $\x\pb{i}$ (\eg users),
there %is %have not one, but a set of
are multiple associated outputs %$\{ y\pb{ij} \}_{j=1:n^i}$ (\eg movies).
$\{ \y\pb{ij} \}_{j=1}^{n^i}$ (\eg trajectories they have visited).
Indeed, the existence of multiple outputs is the basis on which even non-structured recommendation systems are built, as one looks to exploit signal embedded in the aggregate information.
For model learning, structured prediction approaches do not have a standard way to take into account multiple output sequences %$\{ \y\pb{ij} \}_{j=1:n^i}$
for each input %$\x\pb{i}$
yet.

On the other hand, for typical recommender systems problems, one assumes that the outputs are non-structured (\eg real-valued ratings for movies).
Thus, making a prediction involves enumerating all {\em non-structured} items $y$ in order to compute $\argmax_y f(\x,y)$.
For structured recommendation problems, computing $\argmax_\y f(\x,\y)$ is harder since it is often impossible to efficiently enumerate $\y$ (\eg all possible trajectories in a city).

In the rest of this section, we will first review the background of structured prediction problems (Sec~\ref{ssec:ssvm}), then present a model for structured recommendation (Sec~\ref{ssec:sr}), followed by algorithms for its learning (Sec~\ref{ssec:subtour}) and inference (Sec~\ref{ssec:SRinf}).

% In many practical
% problems we may observe more than one label for the same set of features, which violates
% the implicit assumptions of many learning algorithms. In this work we explicitly consider
% all observed labels of a particular example to be useful for training, that is we use
% the multiset of ground truths in training.
% In particular we focus on the structured prediction case,
% where the output of the classifier is from a large set $\mathcal{Y}$ with internal structure.
% An example of this is when $y\in\mathcal{Y}$ is a sequence of binary values.
% Given an example $x_i$ there may be multiple label sequences $y_{ij}$, where $j=1,...,J$.

\eat{
Suggested order:
\begin{enumerate}
  \item structured SVM
  \item multiset SSVM
  \item list Viterbi for multiple ground truths
\end{enumerate}

Then focus on trajectory
\begin{enumerate}
  \item Trajectory recommendation
  \item ILP for subtour elimination
  \item 2 uses of list Viterbi
  \begin{itemize}
    \item multiple ground truths
    \item subtour elimination
  \end{itemize}
\end{enumerate}
}

\secmoveup
\subsection{Preliminaries: structured SVMs}
\label{ssec:ssvm}
\textmoveup

%In structured prediction, the output of classifier given feature vector $\x$ is
%\begin{equation*}
%\y^* = \argmax_{\y \in \mathcal{Y}}~ f(\x, \y),
%\end{equation*}
%where $\mathcal{Y}_\mathbf{x}$ is the set of all possible trajectories with POIs in $\mathcal{P}$ and satisfying query $\mathbf{x}$,
One well known model for structured prediction is the Structured Support Vector Machines (SSVM)~\cite{joachims2009predicting,tsochantaridis2005large}.
This comprises three essential ingredients.

\emph{Score function}. In SSVMs, we specify that the score function $f(\x, \y)$ takes a linear form:
%is a function that scores the compatibility between features $\mathbf{x}$ and a specific label $\mathbf{y}$,
%in the case of structured SVM (SSVM), the compatibility function $f(\mathbf{x}, \mathbf{y})$ for structured SVM is this linear form,
\begin{equation*}
f(\x, \y) = \w^\top \Psi(\x, \y),
\end{equation*}
where $\w$ is a weight vector, and $\Psi(\x, \y)$ is a \emph{joint feature map}
between the input $\x$ and label sequence $\y$.
The design of the feature map $\Psi(\cdot,\cdot)$ is problem specific.
%For many problems, we can assume that it is a vector whose elements represent unary
%terms for each element in the label $y_{1:l}$, and pairwise interactions between the labels.
%For sequence data, in particular, we also assume that the pair-wise interactions are between
%adjacent elements, i.e. $y_j$ and $y_{j+1}$ for $j=1:l-1$.
%Subsequently, the score function $f(\x,\y)$ decomposes into a sum of
%each of these unary and pairwise features with the corresponding feature weight:
%\begin{equation}
%\label{eq:jointfeature}
%\resizebox{0.9\linewidth}{!}{$\displaystyle
%f(\x, \y) =  %\w^\top \Psi(\x,\y)
%\sum_{j=1}^l \w_j^\top \Psi_j(\x, y_j)
%  + \sum_{j=1}^{l-1} \w_{j,j+1}^\top \Psi_{j,j+1}(\x, y_{j}, y_{j+1}). %\nonumber
%  $}
%\end{equation}
%Here, $\Psi_j$ is a feature map between the input and one output label element $y_j$, with a corresponding weight vector $\w_j$
%and $\Psi_{j,j+1}$ is a pairwise feature vector that captures the interactions between consecutive labels $y_j$ and $y_{j+1}$,
%with a corresponding weight vector $\w_{j,j+1}$.

%To learn the parameters, we train the structured SVM by optimising a quadratic program (QP),
\emph{Objective function}.
To learn a suitable set of weights $\w$, SSVMs solve the following optimisation problem:
\begin{equation}
\label{eq:nslack}
\resizebox{0.9\linewidth}{!}{$\displaystyle
\begin{aligned}
&\min_{\w, \, \bm{\xi} \ge 0} ~\frac{1}{2} \w^\top \w + \frac{C}{n} \sum_{i=1}^n \xi_i \\
&s.t.~~  \forall i, \\
%&\w^\top \Psi(\x^{(i)}, \y^{(i)}) + \xi_i \ge
%          \max_{\bar{\y} \in \mathcal{Y}}
%          \left\{\w^\top \Psi(\x^{(i)}, \bar{\y}) + \Delta(\y^{(i)}, \bar{\y}) \right\}. \nonumber
& \w^\top \Psi(\x^{(i)}, \y^{(i)}) - \w^\top \Psi(\x^{(i)}, \bar{\y}) \ge
  \Delta(\y^{(i)}, \bar{\y}) - \xi_i.
\end{aligned}
$}
\end{equation}

Here, $\bar\y$ is an arbitrary candidate sequence,  % \in \mathcal{Y} -- LX: what is cal Y anyway?
and $\Delta(\y, \bar\y)$ is the loss function between $\bar\y$ and the ground truth $\y$,
%%LX: we don't need the def of \xi_i below?
and slack variable $\xi_i$ is the \emph{hinge loss} for the prediction of the $i$-th example~\cite{tsochantaridis2005large},
\resizebox{.99\linewidth}{!}{
\begin{minipage}{\linewidth}
\begin{align*}
\xi_i = \max \left( 0, \, \right.
        & \max_{\bar{\y} \in \mathcal{Y}}
          \left\{ \Delta(\y^{(i)}, \bar{\y}^{(i)}) + \w^\top \Psi(\x^{(i)}, \bar{\y}^{(i)}) \right\} \\
        & \left. - \w^\top \Psi(\x^{(i)}, \y^{(i)}) \right).
\end{align*}
\end{minipage}
}
%This formulation is called "$n$-slack" as we have one slack variable for each example in training set.
Here the inner maximisation is known as the \emph{loss-augmented inference}.
Loss-augmented inference can be efficiently done if loss function $\Delta(,)$ is also decomposable
with respect to individual and pairs of label elements.
% in a way similar to Equation~\eqref{eq:jointfeature}.

To solve problem (\ref{eq:nslack}), one option is to simply enumerate all constraints, and feed the problem into a standard solver.
However, this approach is impractical as there is a constraint for every possible label $\bar{\y}$.
Instead, we can resort to a cutting-plane algorithm which repeatedly solves the quadratic program (\ref{eq:nslack})
with a growing set of constraints~\cite{joachims2009predicting}.
In each iteration, a new constraint is formed by solving the loss-augmented inference,
which helps shrink the feasible region of the problem.

\secmoveup
\subsection{SSVM for recommendation: the SR model}
\label{ssec:sr}
\textmoveup

Recall that the structured recommendation problem
involves observing \emph{multiple} ground truth output sequences for each input.
%If we observed more than one labels for a particular set of features,
The classic SSVM described in Section~\ref{ssec:ssvm} can be easily generalised to capture this setting:
given feature vector $\x^{(i)}$ and the corresponding set of ground truths $\{\y^{(ij)}\}_{j=1}^{n_i}$
where $n_i$ is the number of labels for $\x^{(i)}$,
we can train a \emph{structured recommendation} (\emph{SR}) model by optimising a quadratic program similar to (\ref{eq:nslack}),
\begin{equation}
\label{eq:nslack_ml}
\resizebox{0.9\linewidth}{!}{$
\begin{aligned}
&\min_{\w, \, \bm{\xi} \ge 0} ~ \frac{1}{2} \w^\top \w + \frac{C}{N} \sum_{i=1}^n \sum_{j=1}^{n_i} \xi_{ij} \\
&s.t.~~ \forall i, \, \forall j, \\
& \w^\top \Psi(\x^{(i)}, \y^{(ij)}) - \w^\top \Psi(\x^{(i)}, \bar{\y}^{(i)}) \ge
  \Delta(\y^{(ij)}, \bar{\y}^{(i)}) - \xi_{ij}.
\end{aligned}
$}
\end{equation}
where $N = \sum_i n_i$ and $\bar{\y}^{(i)} \in \mathcal{Y} \setminus \{\y^{(ij)}\}_{j=1}^{n_i}$.
Compared to (\ref{eq:nslack}), the key distinction is that the above
explicitly aggregates all the ground truth labels for each input when generating the constraints,
i.e., the loss-augmented inference becomes
\begin{equation}
\label{eq:loss_aug_inf}
\max_{\bar{\y}^{(i)} \in \ \mathcal{Y} \setminus \{\y^{(ij)}\}_{j=1}^{n_i}}
     \left( \w^\top \Psi(\x^{(i)}, \bar\y^{(i)}) + \Delta(\y^{(ij)}, \bar{\y}^{(i)}) \right).
\end{equation}
In this way, we do not have apparently contradictory constraints where
two ground truth sequences are each required to have larger score than the other.
Instead of using $N$ slack variables as that in (\ref{eq:nslack_ml}),
we can use one slack variable to represent the sum of the $N$ hinge losses in (\ref{eq:nslack_ml}),
which leads to this one-slack formulation,
\begin{equation}
\label{eq:1slack_ml}
\resizebox{0.9\linewidth}{!}{$
\begin{aligned}
& \min_{\w, \, \xi \ge 0} ~\frac{1}{2} \w^\top \w + C \xi \\
& s.t.~~ \frac{1}{N} \left( \sum_{i,j} \w^\top \Psi(\x^{(i)}, \y^{(ij)}) - \w^\top \Psi(\x^{(i)}, \bar{\y}^{(i)}) \right) \\
& \hspace{2em} \ge \frac{1}{N} \sum_{i,j} \Delta(\y^{(ij)}, \bar{\y}^{(i)}) - \xi.
\end{aligned}
$}
\end{equation}
This one-slack formulation can be trained more efficiently than the $N$-slack formulation (\ref{eq:nslack_ml}) and we use it here.
Equation~\ref{eq:nslack_ml} is similar to a ranking objective, as the constraints enforce
that the positively labeled sequences (the known items that the user likes) are scored
higher than all other unseen sequences. Recent work on positive and unlabelled data have
theoretically shown the close relationship between positive and unlabelled learning and two class
classification.



\input{listviterbi}

\secmoveup
\subsection{Inference and learning for SR}
\label{ssec:SRinf}
\textmoveup

For inference in SR model, both ILP and list Viterbi algorithms can be used, and they will generate the
same result if terminated and converged within a given time budget.
List Viterbi algorithms are polynomial time given the list depth $k$,
but in reality $k$ is unknown a priori and can be very large for long sequences
We found that state-of-the-art ILP solvers converge to a solution faster if sequence length $l$ is large.
In the experiments, we use list Viterbi for short sequences, and ILP for long ($l>10$) sequences.

%\TODO{revise this para to describe listViterbi for lost-augmented inf, without loops, and with multiple examples.}
Similar to the loss-augmented inference described in Section~\ref{ssec:ssvm},
we can rewrite the constraints in problem (\ref{eq:nslack_ml}) into
\begin{equation*}
\resizebox{0.99\linewidth}{!}
{$
\w^\top \Psi(\x^{(i)}, \y^{(ij)}) + \xi_{ij} \ge
\max_{\bar{\y}} \left( \Delta(\y^{(ij)}, \bar{\y}) + \w^\top \Psi(\x^{(i)}, \bar{\y}) \right),
$}\eqmoveup
\end{equation*}
Normally, the maximisation at the right side of the above inequality cannot be solved efficiently due to the constraint that
$\bar{\y}$ is in $\mathcal{Y}$,
but should not be in the set of observed labels $\{\y^{(ij)}\}_{j=1}^{n_i}$.
However, we can pretend that $\bar{\y}$ can be any label in $\mathcal{Y}$ and do the unconstrained optimisation,
which can sometimes be solved efficiently, then we filter out the optimal solution if it has been observed,
i.e., in $\{\y^{(ij)}\}_{j=1}^{n_i}$.
In addition to train multiset SSVM, this technique can be further used to deal with other constraints such as sub-tour elimination
%as described in Section~\ref{ssec:subtour}.
as described in Section~\ref{ssec:subtour}.

%\TODO{talk about multiple truths and what it means in prediction}
