% !TEX root = ./main.tex

% \secmoveup
% \section{\trajrec as a Structured Prediction Problem}
% \label{sec:trajrec}
% \textmoveup

% We present the \trajrec problem,
% which shall serve as our canonical application of sequential recommendation.
% We first review the problem as it is typically treated in the literature,
% and then show how it may be viewed as a structured prediction problem.

% \secmoveup
% \subsection{\trajrec: standard view}
% \textbf{\trajrec: standard view}.
% \subsection{The \trajrec problem}
%\textbf{\trajrec}.

%\subsection{Examples of sequence recommendation}
%\label{sec:trajrec}

\section{Related work on sequence recommendation}
\label{sec:related}


We summarise recent work most related to sequence recommendation, 
in particular the problem of trajectory recommendation, music playlist generation, 
and next basket prediction.

%To make the sequence recommendation problem more concrete,
%we provide three specific examples,
%starting with the problem of \trajrec
%that shall serve as a recurring motivation.
%%we explicate how a recently studied problem may be viewed as a special case.
%Note that in all these problems, one is specifically interested in sequences that are paths.

A classic approach for {\bf travel recommendation} is ranking locations with 
collaborative filtering~\cite{zhang2015location,ijcai13};
such approaches do not consider sequence structure.
%collaborative filtering~\cite{shi2011personalized,zhang2015location,ijcai13}.
%or matrix factorisation family of techniques applied to places and trajectories
Another approach regards route recommendation as a planning problem~\cite{brilhante2013shall,gioniswsdm14,ijcai15}.
%The TripBuilder system~\cite{brilhante2013shall} first solves a maximum coverage problem for user preference and then solves TSP for routing. 
%these assume a fixed objective function that is not directly optimised to predict user behaviour. %individual users. 
%A few approaches jointly consider POI preferences and routes~\cite{chen2015tripplanner,cikm16paper}.
%routes~\cite{chen2015tripplanner,kurashima2010geotag,cikm16paper}.
The collaborative filtering approaches rank POI but do not take into account the sequence that a trip is taken.
On the other hand, the planning approaches assume a fixed objective function that is not directly optimised to predict user behaviour.
There have been a few approaches that jointly consider POI preferences and routes~\cite{chen2015tripplanner,cikm16paper}.

% There are, roughly, three problem settings that have been studied.
% The first setting is \emph{point of interest} (\emph{POI}) \emph{recommendation};
% Here, one wishes to rank various POIs in a city in order of how ``interesting'' they are to a given visitor,
% exploiting
% available metadata for each POI~\cite{shi2011personalized,lian2014geomf,hsieh2014mining,yuan2014graph}.
% The second setting is \emph{next location recommendation};
% here, given the sequence of a traveller's partial tour through a city,
% the goal is to recommend which POI the traveller should visit next~\cite{fpmc10,ijcai13,zhang2015location}.
%quantifying tourist traffic flow between points-of-interest~\cite{zheng2012patterns},
%formulating a binary decision or ranking problem~\cite{baraglia2013learnext}, and predicting the next location with
%or sequence models such as recurrent neural networks~\cite{aaai16}.
%The third setting is \emph{\trajrec},
%which is our interest in this paper.


% AKM: not sure these are suitable here
%
% This problem is related to automatic playlist generation,
% where we recommend a sequence of songs given a specified song (a.k.a. the seed) and the number of new songs.
% Formally, given a library of songs and a query $\mathbf{x} = (s, K)$, where $s$ is the seed and $K$ is the number of songs in playlist,
% we produce a list with $K$ songs (without duplication) by maximising the likelihood~\cite{chen2012playlist},
% \begin{equation*}
% %\max_{(y_1,\dots,y_K)} \prod_{k=2}^K \mathbb{P}(y_{k-1} \given y_k),~ y_1 = s ~\text{and}~ y_j \ne y_k,~ j \ne k.
% \mathbf{y}^* = \argmax_{\mathbf{y} \in \mathcal{P}_\mathbf{x}}~ \mathbb{P}(\mathbf{y} \given \mathbf{x}),~ \mathbf{y} = (y_1=s,\dots,y_K)
% ~\text{and}~ y_j \ne y_k ~\text{if}~ j \ne k.
% \end{equation*}

% Another similar problem is choosing a small set of photos from a large photo library and compiling them into a slideshow or movie.

%
%\subsection{\trajrec: structured view}
%\textbf{\trajrec: structured view}.
%\subsection{\trajrec as a structured prediction problem}


%%More abstractly,
%We can view \trajrec as sequence recommendation in the following way:
%given trajectory query $\x$, and a suitable scoring function $f$, we wish to find
%$\mathbf{y}^* = \argmax_{\mathbf{y} \in \mathcal{Y}}~f(\mathbf{x}, \mathbf{y}),$
%%%DW: use top-k prediction formulation or not?
%where $\mathcal{Y}$ is the set of all possible trajectories with POIs in $\mathcal{P}$ that conform to the constraints imposed by the query $\mathbf{x}$.
%In particular,
%$\mathbf{y} = (s,~ y_2, \dots, y_l)$ is a trajectory with $l$ POIs. %, which has no sub-tours. %i.e. $y_j \ne y_k$ if $j \ne k$.
%This was the view proposed in~\cite{cikm16paper} where they authors considered an
%objective function that added two components together: a POI score and a transition score.
%
%Now, our training set of historical trajectories may be written as
%$\{ ( \x\pb{i}, \{ \y\pb{ij} \}_{j=1}^{n_i} ) \}_{i=1}^{n}$,
%where each $\x\pb{i}$ is a distinct query
%with $\{ \y\pb{ij} \}_{j=1}^{n_i}$ the corresponding \emph{set} of observed trajectories.
%Note that we expect most queries to have several distinct trajectories;
%minimally,
%for example,
%there may be two nearby POIs that are visited in interchangeable order by different travellers.
%We are also interested in predicting paths $\y$, since it is unlikely a user will want to visit the same location twice.


{\bf Playlist generation}
%As another example, 
considers recommending playlists (\ie sequences of songs) to users, given a query song~\citep{McFee:2011,chen2012playlist,hidasi2015session}.
A canonical approach is to
learn a latent representation of songs from historical playlists,
and exploit a Markovian assumption on the song transitions;
or to learn high quality transitions using RNNs~\cite{choi2016towards}.
%While a reasonable first order approximation, this assumption limits the modelling power of such approaches.


{\bf Next basket prediction}
is another example, %of sequence recommendation,
%One more example of sequence recommendation is the problem of recommending 
where we recommend the next items a user might like to purchase, given the sequence of their shopping basket purchases~\citep{Rendle:2010,Wang:2015}.
The canonical approach here is to apply matrix factorisation to the Markov chain of transitions between items,
or modelling high quality transitions using RNNs~\cite{yu2016dynamic}.
This method is feasible because one is only interested in predicting %sequences 
one element at a time, instead of predicting a entire sequence given the initial item.



%\subsubsection{Existing approaches}
%
%Existing approaches treat the problem as one of determining a score for the intrinsic appeal of each POI.
%% based on implicit preference data in the training set.
%% Perhaps the simplest such approach is based on learning a model to predict whether a particular POI occurs, or not, in the trajectory corresponding to a query.
%% Formally, from the given set of trajectories
%% we derive a training set $\{ ( \x^{(i)}, p, y^{(i)} ) \}_{i = 1}^n$,
%% where each POI $p$ is augmented with a label $y^{(i)} \in \{ \pm 1 \}$ denoting whether or not it appeared in a trajectory corresponding to the query $\x^{(i)}$.
%% Formally, the objective used for training is
%% $$ \min_{\w} \frac{1}{2} \w^\top \w + C \cdot \sum_{i = 1}^n \sum_{p \in \mathcal{P}} \ell\left( y^{(i)} \cdot ( \w^\top \Phi( \x^{(i)}, p ) ) \right) $$
%% where
%% $\Phi( \cdot, \cdot )$ denotes a query-POI feature mapping,
%% $C > 0$ is some regularisation strength,
%% and $\ell( v )$ is any suitable margin loss, such as the logistic loss $\ell( v ) = \log( 1 + e^{-v} )$.
%% One can use the resulting model to produce a score for any POI $p$ given a new query $\x$,
%% and then pick the top-$l$ scoring POIs to produce a trajectory.
%%%For example, \citep{cikm16paper} proposed a RankSVM model,
%For example, a RankSVM model
%which %is fed as input %pairs $(p_i, p_j)$ of POIs such that $p_i$ appears ahead of $p_j$ in some trajectory.
%learns to predict whether a POI is likely to appear ahead of another POI in a trajectory corresponding to some query~\cite{cikm16paper}.
%Formally,
%from the given set of trajectories
%we derive a training set
%% $\{ ( \x^{(i)}, p, y^{(i)} ) \}_{i = 1}^n$,
%% where each POI $p$ is augmented with a label
%% %$y^{(i)} \in \{ \pm 1 \}$ denoting whether or not
%% $y^{(i)}$ denoting how many times
%% it appeared in a trajectory corresponding to the query $\x^{(i)}$.
%$\{ ( \x^{(i)}, \mathbf{r}^{(i)} ) \}_{i = 1}^n$,
%where for each trajectory query $\x^{(i)}$ there is a list of ranked POI pairs
%$\mathbf{r}^{(i)} \subseteq \mathcal{P} \times \mathcal{P}$
%such that
%$(p, p') \in \mathbf{r}^{(i)}$
%iff
%%POI $p$ is ranked above the POI $p'$ in the trajectories associated with $\x^{(i)}$, %according to some notion.
%%\eg based on the counts of the number of times a POI appears in the trajectories associated with a query.
%POI $p$ appears more times than POI $p'$ in all trajectories associated with $\x^{(i)}$. %according to some notion.
%The training objective is %then
%\begin{align}
%\resizebox{0.909\linewidth}{!}{$\displaystyle
%\displaystyle \min_{\w} ~\frac{1}{2} \w^\top \w + C \cdot \sum_{i = 1}^n \sum_{(p, p') \in \mathbf{r}^{(i)}}
%\ell\left( \w^\top ( \Psi( \x^{(i)}, p ) - \Psi( \x^{(i)}, p' ) ) \right),
%$} \label{eq:ranksvm}
%\end{align}
%for
%feature mapping $\Psi$,
%regularisation strength $C$ % > 0$,
%and squared hinge loss $\ell( v ) = \max( 0, 1 - v )^2$.
%%where $\Phi, C$ are as before,
%% where
%% $\Phi( \cdot, \cdot )$ denotes a query-POI feature mapping,
%% $C > 0$ is some regularisation strength,
%% and $\ell( v ) = \max( 0, 1 - v )^2$ is the squared hinge loss,
%% and
%% %$p \succeq_{\mathbf{x}} p'$ is denoted to mean that the
%% $\mathcal{R}( \x )$
%% denotes all pairs of POIs $(p, p')$ such that
%% POI $p$ is ranked above the POI $p'$ in the trajectories associated with $\x$, %according to some notion.
%% \eg based on the counts of the number of times a POI appears in the trajectories associated with a query.
%%For example, this may be computed by counting the number of times a POI appears in the trajectories associated with a query,
%%and using this to determine which of two POIs is more suitable for a query.



%
% To do this, we show how the problem can be cast as one of sequential recommendation,
% thus allowing us to leverage the tools developed in the previous section.

% Comparing the above to the discussion in the previous section, it is clear that
% we can cast \trajrec as a special case of the structured recommendation problem.
% Consequently, we may approach it using structured prediction methods such as the SSVM,
% as well as the extensions proposed to account for multiple ground truths and eliminate loops during training.

% AKM: repetitive
%
% standard SSVM
% We can learn a recommender by training a SSVM on the set of observed trajectories $\{\mathbf{x}^{(i')}, \mathbf{y}^{(i')}\}_{i'=1}^{N'}$,
% However, we ignore the fact that for the same query, we normally observed more than one trajectory,
% we would like to exploit this fact to better modelling the observed trajectories.

% AKM: repetitive
%
% \subsection{Query Aggregation}
% \label{sec:query}

% To modelling the fact that a given query has multiple observed trajectories,
% we firstly group trajectories according to queries, in other words,
% we now have a dataset $\{\mathbf{x}^{(i)}, \{\mathbf{y}^{(ij)}\}_{j=1}^{N_i}\}_{i=1}^N$
% with $N$ queries and queries $\mathbf{x}^{(i)}$ has $N_i$ trajectories observed.


% \subsection{Recommendation with Multiset SSVM}
% \label{sec:trajrec-ssvm}

% We can learn to recommend trajectories by training a multiset SSVM described in Section~\ref{sec:ssvm-ms}
